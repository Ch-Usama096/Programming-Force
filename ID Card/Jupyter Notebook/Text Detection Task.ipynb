{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from PIL import Image\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add\n",
    "from tensorflow.keras import layers\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f28297",
   "metadata": {},
   "source": [
    "<b>Load Dataset from COCO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f245e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Base Path of the Dataset\n",
    "train_base_path = \"E:/Deep Learning/ID Card/train\"\n",
    "valid_base_path = \"E:/Deep Learning/ID Card/valid\"\n",
    "\n",
    "# Define the Path of the Tarining and Validaton Dataset\n",
    "valid_path = os.path.join(valid_base_path, \"Valid_annotation_coco.json\")\n",
    "train_path = os.path.join(train_base_path, \"train_annotation_coco.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6622e9c3",
   "metadata": {},
   "source": [
    "<b>Read the Valid/Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f5677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Valid Json File\n",
    "file = open(valid_path)  # open the Json File\n",
    "\n",
    "# Load the Data from Json file\n",
    "valid_data = json.load(file) \n",
    "\n",
    "# Clos the Json File\n",
    "file.close()\n",
    "\n",
    "# Read the Train Json File\n",
    "file = open(train_path)  # open the Json File\n",
    "\n",
    "# Load the Data from Json file\n",
    "train_data = json.load(file) \n",
    "\n",
    "# Clos the Json File\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5961391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    # Get the Information of the Images \n",
    "    images_list = {}\n",
    "    for image_data in data[\"images\"]:\n",
    "        image_name = image_data[\"file_name\"]\n",
    "        image_height = image_data[\"height\"]\n",
    "        image_width  = image_data[\"width\"]\n",
    "        image_id = image_data[\"id\"]\n",
    "        images_list[image_id] = [image_name , image_height , image_width]\n",
    "    \n",
    "    # Get the Information of the Category\n",
    "    category_list = []\n",
    "    for category in data[\"categories\"]:\n",
    "        category_list.append(category[\"name\"])\n",
    "    \n",
    "    # Get the Information of the Images Annotations\n",
    "    previous_image_id = \"\"\n",
    "    annotation_list = {}\n",
    "    count = 1\n",
    "    for annotate in data[\"annotations\"]:\n",
    "        image_id = annotate[\"image_id\"]\n",
    "        category_id = annotate[\"category_id\"]\n",
    "        bbox = annotate[\"bbox\"]\n",
    "\n",
    "        if image_id == previous_image_id:\n",
    "            annotation_list[image_id].append(category_id)\n",
    "            annotation_list[image_id].append(bbox)\n",
    "        else:\n",
    "            annotation_list[image_id]   = [category_id , bbox]\n",
    "            previous_image_id = image_id\n",
    "    \n",
    "    return images_list , category_list , annotation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcb4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Information of Train Dataset\n",
    "train_images , train_categories , train_annotations = load_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35919ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Information of Validation Dataset\n",
    "val_images   , val_categories   , val_annotations   = load_data(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f3e21",
   "metadata": {},
   "source": [
    "<b>Draw the Bounding Box in the Traning Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5c7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Iterate the Images \n",
    "\n",
    "for index in range(len(train_images)):\n",
    "    # Extract the Information about Images\n",
    "    image_name   = train_images[index][0]\n",
    "    image_height = train_images[index][1]\n",
    "    image_width  = train_images[index][2]\n",
    "    \n",
    "    # Now Create the Path of the Image\n",
    "    image_path = os.path.join(train_base_path , image_name)\n",
    "    \n",
    "    # Read the Image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "     # Convert the image into numpy array images\n",
    "    cv2_image = np.array(image)\n",
    "            \n",
    "    # Extract the Information about Annotations of the image\n",
    "    data_annotation = train_annotations[index]\n",
    "    for ann_index in range(len(data_annotation)):\n",
    "        if ann_index % 2 != 0:\n",
    "            cv2.rectangle(cv2_image , (int(data_annotation[ann_index][0]) , int(data_annotation[ann_index][1])) , (int(data_annotation[ann_index][0])+int(data_annotation[ann_index][2]) , int(data_annotation[ann_index][1])+int(data_annotation[ann_index][3])) , (0,255,0) , 3)\n",
    "    \n",
    "    # Display the Image\n",
    "    display(Image.fromarray(cv2_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73a699",
   "metadata": {},
   "source": [
    "<b>Preporcessing Train/Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d37d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_data(images_data , image_annotations , base_path):\n",
    "    # Define the List for Images and Annotations\n",
    "    images_list     = []\n",
    "    annotation_list = []\n",
    "\n",
    "    # Iterate the Images\n",
    "    for index in range(len(images_data)):\n",
    "        # Extract the Information about Images\n",
    "        image_name   = images_data[index][0]\n",
    "        image_width  = images_data[index][2]\n",
    "        image_height = images_data[index][1]\n",
    "\n",
    "        # Now Create the Path of the Image\n",
    "        image_path = os.path.join(base_path , image_name)\n",
    "\n",
    "        # Read the Image\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "         # Convert the image into numpy array images & Normalize the Image\n",
    "        cv2_image = np.array(image).astype(\"float64\") / 255.0\n",
    "        resize_image = cv2.resize(cv2_image , (200,200))\n",
    "\n",
    "        # Extract the Information about Annotations of the image\n",
    "        data_annotation = image_annotations[index]\n",
    "        annotation_sm = []\n",
    "        for ann_index in range(len(data_annotation)):\n",
    "            if ann_index % 2 != 0:\n",
    "                # extract the Image BBOX\n",
    "                x      = float(data_annotation[ann_index][0]) / image_width\n",
    "                y      = float(data_annotation[ann_index][1]) / image_height\n",
    "                width  = float(data_annotation[ann_index][2]) / image_width\n",
    "                height = float(data_annotation[ann_index][3]) / image_height\n",
    "\n",
    "                # Append the Image BBOX\n",
    "                annotation_sm.append(x)\n",
    "                annotation_sm.append(y)\n",
    "                annotation_sm.append(width)\n",
    "                annotation_sm.append(height)\n",
    "\n",
    "        # Append the Images in the List\n",
    "        images_list.append(resize_image)\n",
    "\n",
    "        # Append the Image BBOX in the Annotations List\n",
    "        annotation_list.append(annotation_sm)\n",
    "        \n",
    "    # Return the Results\n",
    "    return images_list , annotation_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1226808f",
   "metadata": {},
   "source": [
    "Train Images & Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f32d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Images and Annotation in the List\n",
    "train_images_list , train_annotations_list = list_data(train_images , train_annotations , train_base_path)\n",
    "\n",
    "# Display the Shape of the Images and Annotation\n",
    "print(f\"Shape of Images is     : {np.shape(train_images_list)}\")\n",
    "print(f\"Shape of Annotation is : {np.shape(train_annotations_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623af512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into the Numpy Array\n",
    "train_images_np      = np.array(train_images_list)\n",
    "train_annotations_np = np.array(train_annotations_list)\n",
    "\n",
    "# Display the Shapes of  Images and Annotation\n",
    "print(f\"Shape of Images is     : {train_images_np.shape}\")\n",
    "print(f\"Shape of Annotation is : {train_annotations_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa9d5fd",
   "metadata": {},
   "source": [
    "Validation Images & Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7757ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Images and Annotation in the List\n",
    "val_images_list , val_annotations_list = list_data(val_images , val_annotations , valid_base_path)\n",
    "\n",
    "# Display the Shape of the Images and Annotation\n",
    "print(f\"Shape of Images is     : {np.shape(val_images_list)}\")\n",
    "print(f\"Shape of Annotation is : {np.shape(val_annotations_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4faaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into the Numpy Array\n",
    "val_images_np      = np.array(val_images_list)\n",
    "val_annotations_np = np.array(val_annotations_list)\n",
    "\n",
    "# Display the Shape of the Images and Annotation\n",
    "print(f\"Shape of Images is     : {val_images_np.shape}\")\n",
    "print(f\"Shape of Annotation is : {val_annotations_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08886e4e",
   "metadata": {},
   "source": [
    "<b>Build CNN Feature Extraction Text Detection in the ID Card Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5eb43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model of CNN \n",
    "feature_extractor = Sequential()\n",
    "\n",
    "# Create the Convolutional Layers\n",
    "feature_extractor.add(Conv2D(32, kernel_size=(9, 9), activation='relu', input_shape=(200, 200, 3)))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "\n",
    "feature_extractor.add(Conv2D(96, kernel_size=(7, 7), activation='relu' ))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "\n",
    "\n",
    "feature_extractor.add(MaxPooling2D(pool_size=(3, 3) , strides=(3, 3)))\n",
    "\n",
    "feature_extractor.add(Conv2D(128, kernel_size=(3,3) , strides=(2,2) , padding=\"valid\"))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "\n",
    "feature_extractor.add(Conv2D(filters=1024, kernel_size=(3, 3), strides=(3,3) ,  padding='valid'))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "feature_extractor.add(MaxPooling2D())\n",
    "\n",
    "# Flatten the Feature Extractor\n",
    "feature_extractor.add(Flatten())\n",
    "\n",
    "# Display the Summary of the Feature Extractor\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c9c38",
   "metadata": {},
   "source": [
    "<b>Text Detection Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Obect of Random Forest Classifier\n",
    "rf = RandomForestRegressor(n_estimators = 1000 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1285ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Dataset with Features Extractor \n",
    "x_rf_data = feature_extractor.predict(train_images_np)\n",
    "\n",
    "# Display the Shape of the X_RF_DATA\n",
    "print(f\"Shape of the X Data for RF is : {x_rf_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39cc7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Random Forest Classifier in Training Dataset\n",
    "rf.fit(x_rf_data , train_annotations_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Ranfom Forest Regressor\n",
    "with open('C:/Users/User131022/Desktop/New folder/model.pkl', 'wb') as file:\n",
    "    pickle.dump(rf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64590793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Random Forest Regressor\n",
    "with open('C:/Users/User131022/Desktop/New folder/model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e979f1",
   "metadata": {},
   "source": [
    "<b>Predict the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461bfc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image path\n",
    "image_path = \"E:\\\\Deep Learning\\\\ID Card\\\\test\\\\1.jpg\"\n",
    "\n",
    "# Read the Image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Get the Width & Height of the Image\n",
    "w,h = image.size\n",
    "\n",
    "# Resize the Image\n",
    "resie_image = image.resize((200,200))\n",
    "\n",
    "# Convert the Image into Numpy Array\n",
    "cv2_image = np.array(resie_image).astype(\"float64\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e935ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the Image\n",
    "image_batch = np.expand_dims(cv2_image, axis=0)\n",
    "\n",
    "# Get the Fetuare of the Image\n",
    "feature_image = feature_extractor.predict(image_batch)\n",
    "\n",
    "# Predict the Images\n",
    "prediction = model.predict(feature_image)[0]\n",
    "\n",
    "# Convert the again Numpy Array\n",
    "res_image = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2805908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index in range(len(prediction)):\n",
    "    x = int(prediction[count] * w)\n",
    "    count += 1\n",
    "    y = int(prediction[count] * h)\n",
    "    count += 1\n",
    "    width = int(prediction[count] * w)\n",
    "    count += 1\n",
    "    height = int(prediction[count] * h)\n",
    "    cv2.rectangle(res_image, (x,y) , (x+width , y+height) , (255,0,0) , 3)\n",
    "    count += 1\n",
    "    if count == len(prediction):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image.fromarray(res_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec9ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
